# engine.py (FIXED / MERGED / FULL)
import os
import re
import json
import requests
from datetime import datetime, timedelta, date

import pandas as pd
import streamlit as st
from supabase import create_client, Client

# (Optional) Gemini SDK
try:
    import google.generativeai as genai
except Exception:
    genai = None


# =============================================================================
# Secrets & Clients
# =============================================================================

def _safe_secrets() -> dict:
    try:
        _ = st.secrets
        return dict(st.secrets)
    except Exception:
        return {}

SECRETS = _safe_secrets()

SUPABASE_URL = SECRETS.get("SUPABASE_URL", os.getenv("SUPABASE_URL", "https://qipphcdzlmqidhrjnjtt.supabase.co")).strip()
SUPABASE_KEY = SECRETS.get("SUPABASE_KEY", os.getenv("SUPABASE_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFpcHBoY2R6bG1xaWRocmpuanR0Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjY5NTIwMTIsImV4cCI6MjA4MjUyODAxMn0.AsuvjVGCLUJF_IPvQevYASaM6uRF2C6F-CjwC3eCNVk")).strip()
GEMINI_API_KEY = SECRETS.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY", "AIzaSyAQaiwm46yOITEttdr0ify7duXCW3TwGRo")).strip()

# Hybrid plan table name (configurable)
HYBRID_PLAN_TABLE = SECRETS.get("HYBRID_PLAN_TABLE", "production_plan_2026_01")
HYBRID_HIST_TABLE = SECRETS.get("HYBRID_HIST_TABLE", "production_investigation")

# Legacy default year (configurable)
LEGACY_DEFAULT_YEAR = str(SECRETS.get("LEGACY_DEFAULT_YEAR", "2025"))

# Hybrid config
HYBRID_TEST_MODE = bool(SECRETS.get("HYBRID_TEST_MODE", True))
HYBRID_TODAY_STR = str(SECRETS.get("HYBRID_TODAY", "2026-01-05"))
HYBRID_FROZEN_DAYS = int(SECRETS.get("HYBRID_FROZEN_DAYS", 3))

CAPA_LIMITS_DEFAULT = SECRETS.get("CAPA_LIMITS", {"ì¡°ë¦½1": 3300, "ì¡°ë¦½2": 3700, "ì¡°ë¦½3": 3600})

# Hybrid report style config (restore "ìˆ˜ì‚¬ ë¦¬í¬íŠ¸" ëŠë‚Œ)
HYBRID_REPORT_STYLE = str(SECRETS.get("HYBRID_REPORT_STYLE", "investigation")).lower()  # investigation | simple
HYBRID_DEFAULT_TARGET_UTIL = float(SECRETS.get("HYBRID_DEFAULT_TARGET_UTIL", 0.81))  # ì˜ˆì‹œ ë¦¬í¬íŠ¸ì˜ 81%
HYBRID_TARGET_ROUNDING = int(SECRETS.get("HYBRID_TARGET_ROUNDING", 100))  # ëª©í‘œ ìˆ˜ëŸ‰ ë°˜ì˜¬ë¦¼ ë‹¨ìœ„(100ë‹¨ìœ„ ë“±)


@st.cache_resource
def init_supabase() -> Client | None:
    if not SUPABASE_URL or not SUPABASE_KEY:
        return None
    try:
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    except Exception:
        return None

supabase: Client | None = init_supabase()

if genai and GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception:
        pass


# =============================================================================
# Router
# =============================================================================

HYBRID_INTENT_WORDS = [
    "ê°ì¶•", "ì¤„ì—¬", "ì¤„ì´ê³ ", "ë‚®ì¶°", "ì¤„ì—¬ì¤˜",
    "ì¦ëŸ‰", "ëŠ˜ë ¤", "ëŠ˜ë¦¬ê³ ", "ì¶”ê°€", "ìƒ˜í”Œ",
    "ì´ì†¡", "ì˜®ê²¨", "ì—°ê¸°", "ë¯¸ë¤„", "ë‹¹ê²¨", "ì„ í–‰",
    "ê°€ë™ë¥ ", "ëª©í‘œ", "ë§ì¶°", "í•˜ì´ë¸Œë¦¬ë“œ", "ìˆ˜ì‚¬", "ê²€ì¦", "ì „ëµ",
]
LEGACY_FORCE_WORDS = [
    "ì‚¬ë¡€", "ì´ìŠˆ",
    "ë¸Œë¦¬í•‘", "ì›”ê°„",
    "ì´ˆê³¼",  # "CAPA ì´ˆê³¼"ëŠ” ë ˆê±°ì‹œê°€ ë” ìì—°ìŠ¤ëŸ¬ì›€(ì›” ë‹¨ìœ„ ì¡°íšŒ)
    "fan", "motor", "flange", "íŒ¬", "ëª¨í„°", "í”Œëœì§€",
    "0ì°¨", "ìµœì¢…", "ë‚©ê¸°", "ìƒì‚°ì¼",
]

def _extract_year(prompt: str, default_year: str) -> str:
    m = re.search(r"(20\d{2})\s*ë…„", prompt)
    if m:
        return m.group(1)
    m = re.search(r"(20\d{2})-(\d{1,2})-(\d{1,2})", prompt)
    if m:
        return m.group(1)
    return default_year

def _get_hybrid_today() -> date:
    if HYBRID_TEST_MODE:
        try:
            return datetime.strptime(HYBRID_TODAY_STR, "%Y-%m-%d").date()
        except Exception:
            return date(2026, 1, 5)
    return datetime.now().date()

def _extract_date_any(prompt: str, default_year: str = "2026") -> str | None:
    """
    Returns YYYY-MM-DD if found.
    Supports:
      - YYYY-MM-DD
      - M/D
      - Mì›” Dì¼
      - ì˜¤ëŠ˜/ë‚´ì¼/ëª¨ë ˆ (uses hybrid TODAY)
    """
    p = prompt.strip()

    if any(k in p for k in ["ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ"]):
        today = _get_hybrid_today()
        if "ì˜¤ëŠ˜" in p:
            return today.strftime("%Y-%m-%d")
        if "ë‚´ì¼" in p:
            return (today + timedelta(days=1)).strftime("%Y-%m-%d")
        if "ëª¨ë ˆ" in p:
            return (today + timedelta(days=2)).strftime("%Y-%m-%d")

    m = re.search(r'(20\d{2})-(\d{1,2})-(\d{1,2})', p)
    if m:
        yy, mm, dd = m.groups()
        return f"{int(yy):04d}-{int(mm):02d}-{int(dd):02d}"

    m = re.search(r'(\d{1,2})/(\d{1,2})', p)
    if m:
        mm, dd = m.groups()
        return f"{int(default_year):04d}-{int(mm):02d}-{int(dd):02d}"

    m = re.search(r'(\d{1,2})ì›”\s*(\d{1,2})ì¼', p)
    if m:
        mm, dd = m.groups()
        return f"{int(default_year):04d}-{int(mm):02d}-{int(dd):02d}"

    return None

def _has_adjustment_intent(prompt: str) -> bool:
    p = prompt.lower()
    if re.search(r"\d+\s*%", p):
        return True
    return any(w in p for w in [x.lower() for x in HYBRID_INTENT_WORDS])

def classify_route(prompt: str) -> tuple[str, dict]:
    meta = {}

    if "ì‚¬ë¡€" in prompt:
        meta["reason"] = "force_legacy_case"
        return "legacy", meta

    p_lower = prompt.lower()

    if any(w.lower() in p_lower for w in [x.lower() for x in LEGACY_FORCE_WORDS]):
        if _has_adjustment_intent(prompt):
            meta["reason"] = "legacy_word_but_adjustment_intent"
            return "hybrid", meta
        meta["reason"] = "force_legacy_words"
        return "legacy", meta

    if ("capa" in p_lower or "ì¹´íŒŒ" in prompt) and not _has_adjustment_intent(prompt):
        meta["reason"] = "capa_lookup_legacy"
        return "legacy", meta

    if _has_adjustment_intent(prompt):
        meta["reason"] = "adjustment_intent"
        return "hybrid", meta

    meta["reason"] = "default_legacy"
    return "legacy", meta


# =============================================================================
# Legacy
# =============================================================================

def extract_date_info_legacy(text: str, default_year: str):
    year = _extract_year(text, default_year)
    info = {"date": None, "month": None, "year": year}

    m = re.search(r"(20\d{2})-(\d{1,2})-(\d{1,2})", text)
    if m:
        yy, mm, dd = m.groups()
        info["year"] = yy
        info["month"] = int(mm)
        info["date"] = f"{int(yy):04d}-{int(mm):02d}-{int(dd):02d}"
        return info

    match_date = re.search(r"(\d{1,2})ì›”\s*(\d{1,2})ì¼", text)
    if match_date:
        mm, dd = match_date.groups()
        info["month"] = int(mm)
        info["date"] = f"{int(info['year']):04d}-{int(mm):02d}-{int(dd):02d}"
        return info

    match_month = re.search(r"(\d{1,2})ì›”", text)
    if match_month:
        info["month"] = int(match_month.group(1))

    return info

def extract_version(text: str) -> str:
    if "0ì°¨" in text or "ì´ˆê¸°" in text or "ê³„íš" in text:
        return "0ì°¨"
    return "ìµœì¢…"

def extract_product_keyword(text: str) -> str | None:
    ignore_words = [
        "ìƒì‚°ëŸ‰","ì•Œë ¤ì¤˜","ë¹„êµí•´ì¤˜","ë¹„êµ","ì œí’ˆ","ìµœì¢…","0ì°¨","ì›”","ì¼","capa","ì¹´íŒŒ",
        "ì´ˆê³¼","ì–´ë–»ê²Œ","ë¼","ìˆì–´","ì‚¬ë¡€","ì´","ì›”ê°„","ë¸Œë¦¬í•‘",
        "fan","motor","flange","íŒ¬","ëª¨í„°","í”Œëœì§€",
        "ì¡°ë¦½1","ì¡°ë¦½2","ì¡°ë¦½3",
        "ëŠ˜ë ¤","ì¦ëŸ‰","ì¦ê°€",
    ]
    words = text.split()
    for w in words:
        clean = re.sub(r"[^a-zA-Z0-9ê°€-í£]", "", w)
        if clean and clean.lower() not in [x.lower() for x in ignore_words] and not re.match(r"\d+(ì›”|ì¼)", clean):
            return clean
    return None

def normalize_line_name(line_val):
    s = str(line_val).strip()
    if s == "1": return "ì¡°ë¦½1"
    if s == "2": return "ì¡°ë¦½2"
    if s == "3": return "ì¡°ë¦½3"
    if "ì¡°ë¦½" in s: return s
    return s

def normalize_date(date_val):
    if not date_val:
        return ""
    s = str(date_val).strip()
    return s[:10] if len(s) >= 10 else s

def _is_month_total_query(user_input: str) -> bool:
    u = user_input.replace(" ", "")
    # "00ì›” ì´ ìƒì‚°ëŸ‰", "00ì›” ì´ìƒì‚°ëŸ‰", "00ì›” ìƒì‚°ëŸ‰(ì´)" ë“±
    if "ì›”" not in u:
        return False
    if "ì´" in u and "ìƒì‚°" in u:
        return True
    # "00ì›” ìƒì‚°ëŸ‰ ì•Œë ¤ì¤˜" ê°™ì€ ì§ˆì˜ë„ ì´ ìƒì‚°ëŸ‰ìœ¼ë¡œ ì·¨ê¸‰(ì œí’ˆí‚¤ì›Œë“œ ì—†ì„ ë•Œë§Œ ì ìš©)
    if "ìƒì‚°ëŸ‰" in u and ("ì•Œë ¤ì¤˜" in u or "ì•Œë ¤" in u or "ì–¼ë§ˆ" in u):
        return True
    return False

def fetch_db_data_legacy(user_input: str) -> str:
    if supabase is None:
        return "SUPABASE_URL/SUPABASE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ DB ì¡°íšŒë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”."

    info = extract_date_info_legacy(user_input, LEGACY_DEFAULT_YEAR)
    target_date = info["date"]
    target_month = info["month"]
    target_version = extract_version(user_input)
    product_key = extract_product_keyword(user_input)

    try:
        # =====================================================================
        # 0) ìƒì‚°ëŸ‰ ì¦ëŸ‰ ì‚¬ë¡€ ê²€ìƒ‰ (NEW - ìµœìš°ì„  ìˆœìœ„)
        # =====================================================================
        if ("ëŠ˜ë ¤" in user_input or "ì¦ëŸ‰" in user_input or "ì¦ê°€" in user_input) and "ì‚¬ë¡€" in user_input:
            query = supabase.table("final_issue").select("ë‚ ì§œ, í’ˆëª©ëª…, ìƒì‚°ëŸ‰, final_role, final_remark")
            query = query.or_("final_remark.ilike.%ê¸´ê¸‰ ë¬¼ëŸ‰ ì¦ëŸ‰%,final_remark.ilike.%í’ˆëª©ê°„ ê°„ì„­%")
            response = query.execute()
            
            if response.data:
                date_groups = {}
                for item in response.data:
                    date_key = normalize_date(item.get('ë‚ ì§œ', ''))
                    if not date_key:
                        continue
                    if date_key not in date_groups:
                        date_groups[date_key] = {'ì„ ìˆœìœ„': [], 'í›„ìˆœìœ„': []}
                    
                    role = item.get('final_role', '')
                    if 'ì„ ìˆœìœ„' in role:
                        date_groups[date_key]['ì„ ìˆœìœ„'].append(item)
                    elif 'í›„ìˆœìœ„' in role:
                        date_groups[date_key]['í›„ìˆœìœ„'].append(item)
                
                valid_cases = []
                for date_key, roles in date_groups.items():
                    if roles['ì„ ìˆœìœ„'] and roles['í›„ìˆœìœ„']:
                        valid_cases.append({
                            'date': date_key,
                            'increased': roles['ì„ ìˆœìœ„'],
                            'decreased': roles['í›„ìˆœìœ„']
                        })
                
                if valid_cases:
                    context = "[PRODUCTION_INCREASE CASE FOUND]\n"
                    context += "Title: ìƒì‚°ëŸ‰ ì¦ëŸ‰ ì‚¬ë¡€ (í’ˆëª©ê°„ ìš°ì„ ìˆœìœ„ ì¡°ì •)\n"
                    context += "Data:\n"
                    
                    for case in valid_cases[:3]:
                        context += f"\n[ë‚ ì§œ: {case['date']}]\n"
                        context += "ì¦ê°€(ì„ ìˆœìœ„):\n"
                        for item in case['increased']:
                            context += f"  - {item['í’ˆëª©ëª…']}: {item['ìƒì‚°ëŸ‰']}\n"
                        context += "ê°ì†Œ(í›„ìˆœìœ„):\n"
                        for item in case['decreased']:
                            context += f"  - {item['í’ˆëª©ëª…']}: {item['ìƒì‚°ëŸ‰']}\n"
                    
                    return context
                else:
                    return "ê°™ì€ ë‚ ì§œì— ì„ ìˆœìœ„ ì¦ê°€ì™€ í›„ìˆœìœ„ ê°ì†Œê°€ í•¨ê»˜ ë°œìƒí•œ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                return "ìƒì‚°ëŸ‰ ì¦ëŸ‰ ê´€ë ¨ ê³¼ê±° ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 1) ê³¼ê±° ì´ìŠˆ ì‚¬ë¡€
        # =====================================================================
        if "ì‚¬ë¡€" in user_input:
            issue_mapping = {
                "MDL1": {"keywords": ["ë¨¼ì €", "ì¤„ì—¬", "ìˆœìœ„", "êµì²´"], "db_text": "ìƒì‚°ìˆœìœ„ ì¡°ì •",
                         "title": "MDL1: ë¯¸ë‹¬(ìƒì‚°ìˆœìœ„ ì¡°ì •/ëª¨ë¸ êµì²´)"},
                "MDL2": {"keywords": ["ê°ì‚¬", "ì •ì§€", "ì„¤ë¹„", "ë¼ì¸ì „ì²´"], "db_text": "ë¼ì¸ì „ì²´ì´ìŠˆ",
                         "title": "MDL2: ë¯¸ë‹¬(ë¼ì¸ì „ì²´ì´ìŠˆ/ì„¤ë¹„)"},
                "MDL3": {"keywords": ["ë¶€í’ˆ", "ìì¬", "ê²°í’ˆ", "ìˆ˜ê¸‰", "ì•ˆë˜ëŠ”"], "db_text": "ìì¬ê²°í’ˆ",
                         "title": "MDL3: ë¯¸ë‹¬(ë¶€í’ˆìˆ˜ê¸‰/ìì¬ê²°í’ˆ)"},
                "PRP": {"keywords": ["ì„ í–‰", "ë¯¸ë¦¬", "ë‹¹ê²¨", "ë•¡ê²¨"], "db_text": "ì„ í–‰ ìƒì‚°",
                        "title": "PRP: ì„ í–‰ ìƒì‚°(ìˆ™ì œ ë¯¸ë¦¬í•˜ê¸°)"},
                "SMP": {"keywords": ["ìƒ˜í”Œ", "ê¸´ê¸‰"], "db_text": "ê³„íšì™¸ ê¸´ê¸‰ ìƒì‚°",
                        "title": "SMP: ê³„íšì™¸ ê¸´ê¸‰ ìƒì‚°"},
                "CCL": {"keywords": ["ì·¨ì†Œ"], "db_text": "ê³„íš ì·¨ì†Œ", "title": "CCL: ê³„íš ì·¨ì†Œ/ë¼ì¸ ê°€ë™ì¤‘ë‹¨"},
            }
            detected_code = None
            for code, meta in issue_mapping.items():
                if any(k in user_input for k in meta["keywords"]):
                    detected_code = code
                    break

            if detected_code:
                meta = issue_mapping[detected_code]
                query = supabase.table("production_issue_analysis_8_11") \
                    .select("í’ˆëª©ëª…, ë‚ ì§œ, ê³„íš_v0, ì‹¤ì _v2, ëˆ„ì ì°¨ì´_Gap, ìµœì¢…_ì´ìŠˆë¶„ë¥˜")

                if detected_code == "MDL2":
                    query = query.or_("ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ë¼ì¸ì „ì²´ì´ìŠˆ%,ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ì„¤ë¹„%")
                elif detected_code == "MDL3":
                    query = query.or_("ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ë¶€í’ˆìˆ˜ê¸‰%,ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ìì¬ê²°í’ˆ%")
                else:
                    query = query.ilike("ìµœì¢…_ì´ìŠˆë¶„ë¥˜", f"%{meta['db_text']}%")

                res = query.limit(3).execute()
                if res.data:
                    return (
                        f"[CODE CASE FOUND]\n"
                        f"Code: {detected_code}\n"
                        f"Title: {meta['title']}\n"
                        f"Data: {json.dumps(res.data, ensure_ascii=False)}"
                    )
                return "ê´€ë ¨ëœ ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 2) ì›”ê°„ ì´ ìƒì‚°ëŸ‰ ë¸Œë¦¬í•‘ (ë‘ ë‹¬ ì´ìƒ)
        # =====================================================================
        found_months = re.findall(r"(\d{1,2})ì›”", user_input)
        found_months = sorted(list(set([int(m) for m in found_months])))

        if len(found_months) >= 2 and product_key is None:
            target_ver = extract_version(user_input)
            res = supabase.table("monthly_production") \
                .select("ì›”, ì´_ìƒì‚°ëŸ‰") \
                .in_("ì›”", found_months) \
                .eq("ë²„ì „", target_ver) \
                .execute()
            if res.data:
                df = pd.DataFrame(res.data).sort_values(by="ì›”")
                out = [f"[{target_ver} ì›”ê°„ ì´ ìƒì‚°ëŸ‰ ë¸Œë¦¬í•‘]"]
                prev_val, prev_month = None, None
                for _, row in df.iterrows():
                    m = row["ì›”"]
                    val = row["ì´_ìƒì‚°ëŸ‰"]
                    msg = f"{m}ì›”: {val:,}"
                    if prev_val is not None:
                        diff = val - prev_val
                        if diff > 0:
                            msg += f" (ì „ì›”({prev_month}ì›”) ëŒ€ë¹„ {diff:,} ì¦ê°€)"
                        elif diff < 0:
                            msg += f" (ì „ì›”({prev_month}ì›”) ëŒ€ë¹„ {abs(diff):,} ê°ì†Œ)"
                        else:
                            msg += " (ë³€ë™ ì—†ìŒ)"
                    out.append(f"- {msg}")
                    prev_val, prev_month = val, m
                return "\n".join(out)
            return "ìš”ì²­í•˜ì‹  ì›”ì˜ ë°ì´í„°ê°€ monthly_production í…Œì´ë¸”ì— ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 2-1) [FIX] ë‹¨ì¼ ì›” ì´ ìƒì‚°ëŸ‰ ("00ì›” ì´ ìƒì‚°ëŸ‰ ì•Œë ¤ì¤˜")
        # =====================================================================
        if target_month and product_key is None and not target_date and _is_month_total_query(user_input):
            res = supabase.table("monthly_production") \
                .select("ì›”, ì´_ìƒì‚°ëŸ‰") \
                .eq("ì›”", target_month) \
                .eq("ë²„ì „", target_version) \
                .limit(1) \
                .execute()
            if res.data:
                row = res.data[0]
                return f"[{row['ì›”']}ì›” {target_version} ì´ ìƒì‚°ëŸ‰]: {int(row['ì´_ìƒì‚°ëŸ‰']):,}"
            return f"{target_month}ì›” {target_version} ì´ ìƒì‚°ëŸ‰ ë°ì´í„°ê°€ monthly_production í…Œì´ë¸”ì— ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 3) ì›” CAPA ì¡°íšŒ
        # =====================================================================
        if target_month and (("capa" in user_input.lower()) or ("ì¹´íŒŒ" in user_input)) \
           and "ë¹„êµ" not in user_input and "ì´ˆê³¼" not in user_input and not target_date:
            res = supabase.table("daily_capa") \
                .select("ë¼ì¸, capa") \
                .eq("ì›”", target_month) \
                .eq("ë²„ì „", target_version) \
                .execute()
            if res.data:
                df = pd.DataFrame(res.data)
                df["ë¼ì¸"] = df["ë¼ì¸"].apply(normalize_line_name)
                grouped = df.groupby("ë¼ì¸")["capa"].apply(list).to_dict()
                display = {}
                for line, capas in grouped.items():
                    uniq = sorted(list(set(capas)))
                    display[line] = uniq[0] if len(uniq) == 1 else uniq
                return f"[{target_month}ì›” {target_version} ë¼ì¸ë³„ CAPA ì •ë³´]: {display}"
            return f"{target_month}ì›” {target_version} CAPA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 4) CAPA ì´ˆê³¼/ë¹„êµ (ì›” ë‹¨ìœ„)
        # =====================================================================
        if ("ì´ˆê³¼" in user_input and "ì›”" in user_input) or ("ë¹„êµ" in user_input and "ì›”" in user_input and product_key is None):
            res_capa = supabase.table("daily_capa").select("*").eq("ì›”", target_month).eq("ë²„ì „", "ìµœì¢…").execute()
            res_prod = supabase.table("daily_total_production").select("*").eq("ì›”", target_month).eq("ë²„ì „", "ìµœì¢…").execute()
            if not res_capa.data or not res_prod.data:
                return "ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨(ì›”/ë²„ì „ í™•ì¸ í•„ìš”)"

            capa_ref = {}
            for it in res_capa.data:
                capa_ref[normalize_line_name(it["ë¼ì¸"])] = it["capa"]

            over = []
            for row in res_prod.data:
                d = normalize_date(row["ë‚ ì§œ"])
                line = normalize_line_name(row["ë¼ì¸"])
                qty = row["ì´_ìƒì‚°ëŸ‰"]
                limit = capa_ref.get(line, 0)
                if limit > 0 and qty > limit:
                    over.append(f"| {d} | {line} | {limit} | {qty} |")

            if "ì´ˆê³¼" in user_input:
                if over:
                    over.sort()
                    return "[CAPA ì´ˆê³¼ ë¦¬ìŠ¤íŠ¸]\n" + "\n".join(over)
                return f"{target_month}ì›” ì‹¤ì ì„ ê²€í† í–ˆìœ¼ë‚˜ CAPA ì´ˆê³¼í•œ ë‚ ì´ ì—†ìŠµë‹ˆë‹¤."
            return f"{target_month}ì›” ë°ì´í„° ë¹„êµ ì™„ë£Œ"

        # =====================================================================
        # 5) êµ¬ë¶„ í•©ê³„(Fan/Motor/Flange)
        # =====================================================================
        gubun_keywords = ["fan","motor","flange","íŒ¬","ëª¨í„°","í”Œëœì§€"]
        if target_month and any(k in user_input.lower() for k in gubun_keywords):
            if "fan" in user_input.lower() or "íŒ¬" in user_input:
                g = "Fan"
            elif "motor" in user_input.lower() or "ëª¨í„°" in user_input:
                g = "Motor"
            else:
                g = "Flange"

            res = supabase.table("production_data") \
                .select("ìƒì‚°ëŸ‰") \
                .eq("ì›”", target_month) \
                .eq("ë²„ì „", "ìµœì¢…") \
                .ilike("êµ¬ë¶„", f"%{g}%") \
                .execute()
            if res.data:
                total = sum([x["ìƒì‚°ëŸ‰"] for x in res.data])
                return f"[{target_month}ì›” {g} ì´ ìƒì‚°ëŸ‰(ìµœì¢…)]: {total:,}"
            return f"{target_month}ì›” {g} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 6) íŠ¹ì • ì¼ì + ì œí’ˆëª… ìƒì‚°ëŸ‰ (0ì°¨ vs ìµœì¢… ë¹„êµ)
        # =====================================================================
        if target_date and product_key:
            if "ë¹„êµ" in user_input:
                res_v0 = supabase.table("production_data").select("*") \
                    .eq("ë‚©ê¸°ì¼", target_date).eq("ë²„ì „", "0ì°¨").ilike("í’ˆëª…", f"%{product_key}%").execute()
                res_final = supabase.table("production_data").select("*") \
                    .eq("ìƒì‚°ì¼", target_date).eq("ë²„ì „", "ìµœì¢…").ilike("í’ˆëª…", f"%{product_key}%").execute()

                v0_qty = sum([x.get("ìƒì‚°ëŸ‰", 0) for x in (res_v0.data or [])])
                final_qty = sum([x.get("ìƒì‚°ëŸ‰", 0) for x in (res_final.data or [])])

                return (
                    f"[ë¹„êµ ê²°ê³¼ ({target_date} {product_key})]\n"
                    f"- 0ì°¨(ë‚©ê¸°ì¼ ê¸°ì¤€): {v0_qty:,}\n"
                    f"- ìµœì¢…(ìƒì‚°ì¼ ê¸°ì¤€): {final_qty:,}\n"
                )

            ver_col = "ë‚©ê¸°ì¼" if target_version == "0ì°¨" else "ìƒì‚°ì¼"
            res = supabase.table("production_data").select("*") \
                .eq("ë²„ì „", target_version).eq(ver_col, target_date).ilike("í’ˆëª…", f"%{product_key}%").execute()
            if res.data:
                total = sum([x.get("ìƒì‚°ëŸ‰", 0) for x in res.data])
                return f"[ì œí’ˆ ë°ì´í„° ({target_date} {product_key} / {target_version})]\n[ì´ ìƒì‚°ëŸ‰]: {total:,}\nData: {json.dumps(res.data, ensure_ascii=False)}"
            return f"[ì•Œë¦¼] {target_date}ì— '{product_key}' {target_version} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # =====================================================================
        # 7) ì¼ìë³„ ì´ ìƒì‚°ëŸ‰
        # =====================================================================
        if target_date and ("ìƒì‚°ëŸ‰" in user_input):
            res = supabase.table("daily_total_production") \
                .select("ì´_ìƒì‚°ëŸ‰").eq("ë‚ ì§œ", target_date).eq("ë²„ì „", target_version).execute()
            if res.data:
                total = sum([x["ì´_ìƒì‚°ëŸ‰"] for x in res.data])
                return f"[{target_date} {target_version} ì´ ìƒì‚°ëŸ‰]: {total:,} (daily_total í•©ê³„)"

            ver_col = "ë‚©ê¸°ì¼" if target_version == "0ì°¨" else "ìƒì‚°ì¼"
            res_fallback = supabase.table("production_data").select("ìƒì‚°ëŸ‰") \
                .eq(ver_col, target_date).eq("ë²„ì „", target_version).execute()
            if res_fallback.data:
                total = sum([x.get("ìƒì‚°ëŸ‰", 0) for x in res_fallback.data])
                return f"[{target_date} {target_version} ì´ ìƒì‚°ëŸ‰]: {total:,} (item í•©ê³„)"
            return f"[{target_date}] ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        return "ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        return f"ë ˆê±°ì‹œ DB ì¡°íšŒ ì˜¤ë¥˜: {str(e)}"


def query_gemini_legacy(user_input: str, context: str) -> str:
    if not GEMINI_API_KEY:
        return context

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}

    system_prompt = f"""
ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ìƒì‚°ê³„íš ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì œê³µëœ ë°ì´í„°(Context)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ì¤‘ìš”: CAPA ì´ˆê³¼ ë‹µë³€ ê·œì¹™]
Contextì— '[CAPA ì´ˆê³¼ ë¦¬ìŠ¤íŠ¸]'ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¡œ ì¶œë ¥í•˜ì„¸ìš”.

| ë‚ ì§œ | ë¼ì¸ | CAPA | ì´ ìƒì‚°ëŸ‰ |
|---|---|---|---|
| ... | ... | ... | ... |

[ì¤‘ìš”: ìƒì‚°ëŸ‰ ì¦ëŸ‰ ì‚¬ë¡€ ë‹µë³€ ê·œì¹™]
Contextì— [PRODUCTION_INCREASE CASE FOUND]ê°€ ìˆë‹¤ë©´:
1. ë‹µë³€ ìµœìƒë‹¨ì— "# ìƒì‚°ëŸ‰ ì¦ëŸ‰ ì‚¬ë¡€ (í’ˆëª©ê°„ ìš°ì„ ìˆœìœ„ ì¡°ì •)" ì œëª©ì„ ì ìœ¼ì„¸ìš”.
2. ê° ë‚ ì§œë³„ë¡œ ë‹¤ìŒ í˜•ì‹ì˜ í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

**[ë‚ ì§œ: YYYY-MM-DD]**

ì¦ê°€í•œ ì œí’ˆ (ì„ ìˆœìœ„):
| ì œí’ˆëª… | ìƒì‚°ëŸ‰ |
|---|---|
| ... | ... |

ê°ì†Œí•œ ì œí’ˆ (í›„ìˆœìœ„):
| ì œí’ˆëª… | ìƒì‚°ëŸ‰ |
|---|---|
| ... | ... |

3. final_remarkëŠ” í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”.
4. ì—¬ëŸ¬ ë‚ ì§œì˜ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ê°ê° êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”.

[ì¤‘ìš”: ì´ìŠˆ ì½”ë“œ ë‹µë³€ ê·œì¹™]
Contextì— [CODE CASE FOUND]ê°€ ìˆë‹¤ë©´:
1) ë‹µë³€ ìµœìƒë‹¨ì— ì½”ë“œëª…ê³¼ ì œëª©ì„ # Heading 1ë¡œ ì ìœ¼ì„¸ìš”.
2) ë°ì´í„°(Data)ë¥¼ ë°”íƒ•ìœ¼ë¡œ í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”: [ë‚ ì§œ | í’ˆëª©ëª… | ê³„íš(V0) | ì‹¤ì (V2) | ì°¨ì´(Gap)]

[ì¼ë°˜ ë‹µë³€ ê·œì¹™]
1) ìˆ«ìëŠ” ì œê³µëœ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì„¸ìš”.
2) ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—†ë‹¤ê³  í•˜ì„¸ìš”.

[Context Data]
{context}

[User Question]
{user_input}
"""
    data = {"contents": [{"parts": [{"text": system_prompt}]}]}
    try:
        r = requests.post(url, headers=headers, json=data, timeout=60)
        if r.status_code != 200:
            return context
        j = r.json()
        return j["candidates"][0]["content"]["parts"][0]["text"]
    except Exception:
        return context


def run_legacy(prompt: str) -> str:
    ctx = fetch_db_data_legacy(prompt)
    if ("ì˜¤ë¥˜" in ctx) or ("ì„¤ì •ë˜ì§€" in ctx) or ("ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in ctx):
        return ctx
    return query_gemini_legacy(prompt, ctx)


# =============================================================================
# Hybrid
# =============================================================================

TODAY = None
CAPA_LIMITS = None

def initialize_globals(today: date, capa_limits: dict):
    global TODAY, CAPA_LIMITS
    TODAY = today
    CAPA_LIMITS = capa_limits

def hybrid_is_workday_in_db(plan_df, date_str):
    if plan_df.empty or 'is_workday' not in plan_df.columns:
        return False
    row = plan_df[plan_df['plan_date'] == date_str]
    if not row.empty:
        return bool(row.iloc[0].get('is_workday', False))
    return False

def get_workdays_from_db(plan_df, start_date_str, direction='future', days_count=10):
    if plan_df.empty or 'is_workday' not in plan_df.columns:
        return []
    db_dates = plan_df[['plan_date', 'is_workday']].drop_duplicates().sort_values('plan_date')

    if direction == 'future':
        available = db_dates[(db_dates['plan_date'] >= start_date_str) & (db_dates['is_workday'] == True)]
        return available['plan_date'].head(days_count).tolist()

    available = db_dates[(db_dates['plan_date'] < start_date_str) &
                         (db_dates['plan_date'] >= TODAY.strftime('%Y-%m-%d')) &
                         (db_dates['is_workday'] == True)]
    return available['plan_date'].tail(days_count).tolist()

def step1_list_current_stock(plan_df, target_date, target_line):
    current = plan_df[(plan_df['plan_date'] == target_date) & (plan_df['line'] == target_line)].copy()
    if current.empty:
        return None, "í•´ë‹¹ ë‚ ì§œì— ìƒì‚° ê³„íšì´ ì—†ìŠµë‹ˆë‹¤."
    total = int(current['qty_1ì°¨'].sum())
    items = []
    for _, row in current.iterrows():
        q = int(row.get('qty_1ì°¨', 0))
        if q > 0:
            items.append({
                'name': str(row.get('product_name', '')),
                'qty_0ì°¨': int(row.get('qty_0ì°¨', 0)),
                'qty_1ì°¨': q,
                'plt': int(row.get('plt', 1)),
            })
    return {'date': target_date, 'line': target_line, 'total': total, 'items': items}, None

def step2_calculate_cumulative_slack(plan_df, stock_result):
    """
    return list with additional fields for reporting:
      - cumsum_target, cumsum_actual, future_slack
    """
    items_with_slack = []
    for item in stock_result['items']:
        p_name = item['name']
        p_series = plan_df[plan_df['product_name'] == p_name].sort_values('plan_date').copy()
        if p_series.empty:
            continue

        p_series['cumsum_0ì°¨'] = p_series['qty_0ì°¨'].cumsum()
        p_series['cumsum_1ì°¨'] = p_series['qty_1ì°¨'].cumsum()

        today_row = p_series[p_series['plan_date'] == stock_result['date']]
        if today_row.empty:
            continue
        today_row = today_row.iloc[0]

        cumsum_target = int(today_row.get('cumsum_0ì°¨', 0))
        cumsum_actual = int(today_row.get('cumsum_1ì°¨', 0))
        max_movable_cumsum = cumsum_actual - cumsum_target

        future_demand = int(p_series[p_series['plan_date'] > stock_result['date']]['qty_0ì°¨'].sum())
        future_prod = int(p_series[p_series['plan_date'] > stock_result['date']]['qty_1ì°¨'].sum())
        future_slack = int(future_prod - future_demand)

        if max_movable_cumsum > 0:
            max_movable = max_movable_cumsum
        else:
            if future_slack >= 0:
                max_movable = int(item['qty_1ì°¨'])
            else:
                max_movable = max(0, int(item['qty_1ì°¨']) + future_slack)

        due_dates = p_series[p_series['qty_0ì°¨'] > 0]['plan_date'].tolist()
        last_due = max(due_dates) if due_dates else "ë¯¸í™•ì¸"

        if last_due != "ë¯¸í™•ì¸":
            last_due_dt = datetime.strptime(last_due, '%Y-%m-%d').date()
            target_dt = datetime.strptime(stock_result['date'], '%Y-%m-%d').date()
            buffer_days = (last_due_dt - target_dt).days
        else:
            buffer_days = 999

        items_with_slack.append({
            'name': p_name,
            'qty_0ì°¨': int(item.get('qty_0ì°¨', 0)),
            'qty_1ì°¨': int(item['qty_1ì°¨']),
            'plt': int(item['plt']),
            'cumsum_target': int(cumsum_target),
            'cumsum_actual': int(cumsum_actual),
            'future_slack': int(future_slack),
            'max_movable': int(max_movable),
            'last_due': last_due,
            'buffer_days': int(buffer_days),
            'movable': int(max_movable) >= int(item['plt'])
        })
    return items_with_slack

def step3_analyze_destination_capacity(plan_df, target_date, target_line):
    future_workdays = get_workdays_from_db(plan_df, target_date, direction='future', days_count=10)
    capa_status = {}

    for line in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]:
        if line != target_line:
            current = plan_df[(plan_df['plan_date'] == target_date) & (plan_df['line'] == line)]['qty_1ì°¨'].sum()
            remaining = CAPA_LIMITS[line] - current
            capa_status[f"{target_date}_{line}"] = {
                'date': target_date, 'line': line,
                'current': int(current),
                'remaining': int(remaining),
                'max': int(CAPA_LIMITS[line]),
                'usage_rate': (float(current) / float(CAPA_LIMITS[line]) * 100.0) if CAPA_LIMITS[line] else 0.0
            }

        if line == target_line:
            for d in future_workdays:
                current = plan_df[(plan_df['plan_date'] == d) & (plan_df['line'] == line)]['qty_1ì°¨'].sum()
                remaining = CAPA_LIMITS[line] - current
                capa_status[f"{d}_{line}"] = {
                    'date': d, 'line': line,
                    'current': int(current),
                    'remaining': int(remaining),
                    'max': int(CAPA_LIMITS[line]),
                    'usage_rate': (float(current) / float(CAPA_LIMITS[line]) * 100.0) if CAPA_LIMITS[line] else 0.0
                }
    return capa_status

def step4_prepare_constraint_info(items_with_slack, target_line):
    constraint_info = []
    for item in items_with_slack:
        if not item['movable']:
            continue
        is_t6 = "T6" in item['name'].upper()
        is_a2xx = "A2XX" in item['name'].upper()

        if is_t6:
            possible_lines = [l for l in ["ì¡°ë¦½1","ì¡°ë¦½2","ì¡°ë¦½3"] if l != target_line]
            constraint = "ì¡°ë¦½1,2,3 ëª¨ë‘ ê°€ëŠ¥"
            priority = "íƒ€ë¼ì¸ ì´ì†¡ ìš°ì„ "
        elif is_a2xx:
            possible_lines = [l for l in ["ì¡°ë¦½1","ì¡°ë¦½2"] if l != target_line]
            constraint = "ì¡°ë¦½1,2ë§Œ ê°€ëŠ¥(ì¡°ë¦½3 ê¸ˆì§€)"
            priority = "ì¡°ë¦½2 ì´ì†¡ ìš°ì„ "
        else:
            possible_lines = []
            constraint = f"{target_line} ë‚´ ë‚ ì§œ ì´ë™ë§Œ ê°€ëŠ¥"
            priority = "ë™ì¼ë¼ì¸ ì—°ê¸°/ì„ í–‰"

        constraint_info.append({
            **item,
            'possible_lines': possible_lines,
            'is_t6': is_t6,
            'is_a2xx': is_a2xx,
            'constraint': constraint,
            'priority': priority,
        })
    return constraint_info

def _parse_target_percent(prompt: str) -> float | None:
    m = re.search(r"(\d+)\s*%", prompt)
    if m:
        return int(m.group(1)) / 100.0
    return None

def _parse_sample_qty(prompt: str) -> int | None:
    m = re.search(r"ìƒ˜í”Œ\s*(\d+)", prompt)
    if m:
        return int(m.group(1))
    return None

def _parse_add_qty(prompt: str) -> int | None:
    m = re.search(r"ì¶”ê°€\s*(\d+)", prompt)
    if m:
        return int(m.group(1))
    m = re.search(r"(\d+)\s*ì¶”ê°€", prompt)
    if m:
        return int(m.group(1))
    return None

def step6_validate_moves_with_adjust(moves, constraint_info, capa_status, plan_df, target_line):
    valid = []
    violations = []

    def find_item(n): return next((x for x in constraint_info if x['name'] == n), None)

    for i, mv in enumerate(moves or [], 1):
        item_name = mv.get("item")
        qty = int(mv.get("qty", 0))
        to_loc = (mv.get("to") or "").strip()

        item = find_item(item_name)
        if not item:
            violations.append(f"âŒ[{i}] {item_name}: ì´ë™ ê°€ëŠ¥ ëª©ë¡ì— ì—†ìŒ")
            continue

        if qty <= 0:
            violations.append(f"âŒ[{i}] {item_name}: qty<=0")
            continue

        if qty > int(item["max_movable"]):
            violations.append(f"âŒ[{i}] {item_name}: ëˆ„ì ì—¬ìœ  ì´ˆê³¼({qty:,} > {item['max_movable']:,})")
            continue

        if qty % int(item["plt"]) != 0:
            violations.append(f"âŒ[{i}] {item_name}: PLT ë‹¨ìœ„ ì•„ë‹˜(qty%plt!=0)")
            continue

        if "_" not in to_loc:
            violations.append(f"âŒ[{i}] {item_name}: to í˜•ì‹ ì˜¤ë¥˜(YYYY-MM-DD_ë¼ì¸)")
            continue

        to_date, to_line = to_loc.split("_", 1)
        to_date = to_date.strip()
        to_line = to_line.strip()

        if item["is_a2xx"] and to_line == "ì¡°ë¦½3":
            violations.append(f"âŒ[{i}] {item_name}: A2XXëŠ” ì¡°ë¦½3 ê¸ˆì§€")
            continue

        if (not item["is_t6"]) and (not item["is_a2xx"]) and (to_line != target_line):
            violations.append(f"âŒ[{i}] {item_name}: ì „ìš©ëª¨ë¸ íƒ€ë¼ì¸ ê¸ˆì§€")
            continue

        capa_key = f"{to_date}_{to_line}"
        if capa_key not in capa_status:
            violations.append(f"âš ï¸[{i}] {item_name}: ëª©ì ì§€ CAPA ì •ë³´ ì—†ìŒ({capa_key})")
            continue

        if not hybrid_is_workday_in_db(plan_df, to_date):
            violations.append(f"âŒ[{i}] {item_name}: ëª©ì ì§€ {to_date} íœ´ë¬´ì¼")
            continue

        remaining = int(capa_status[capa_key]["remaining"])
        plt = int(item["plt"])

        if qty > remaining:
            adj_plts = remaining // plt
            adj_qty = adj_plts * plt
            if adj_qty >= plt:
                mv = dict(mv)
                mv["original_qty"] = qty
                mv["qty"] = int(adj_qty)
                mv["adjusted"] = True
                violations.append(f"âœ…[{i}] {item_name}: CAPA ë¶€ì¡±ìœ¼ë¡œ ìë™ ì¡°ì •({qty:,} â†’ {adj_qty:,})")
                qty = int(adj_qty)
            else:
                violations.append(f"âŒ[{i}] {item_name}: ëª©ì ì§€ CAPA ë¶€ì¡± ë° ì¡°ì •ë¶ˆê°€(ìš”ì²­ {qty:,}, ì”ì—¬ {remaining:,})")
                continue
        else:
            mv = dict(mv)
            mv["adjusted"] = False

        capa_status[capa_key]["remaining"] = int(capa_status[capa_key]["remaining"]) - int(qty)
        valid.append(mv)

    return valid, violations

@st.cache_data(ttl=600)
def fetch_data_hybrid(target_date: str):
    if supabase is None:
        return pd.DataFrame(), pd.DataFrame()

    dt = datetime.strptime(target_date, "%Y-%m-%d")
    start = (dt - timedelta(days=10)).strftime("%Y-%m-%d")
    end = (dt + timedelta(days=10)).strftime("%Y-%m-%d")

    plan_res = supabase.table(HYBRID_PLAN_TABLE).select("*").gte("plan_date", start).lte("plan_date", end).execute()
    plan_df = pd.DataFrame(plan_res.data)

    hist_df = pd.DataFrame()
    try:
        hist_res = supabase.table(HYBRID_HIST_TABLE).select("*").execute()
        hist_df = pd.DataFrame(hist_res.data)
    except Exception:
        pass

    return plan_df, hist_df

def _pick_target_line(prompt: str, plan_df: pd.DataFrame, target_date: str) -> str | None:
    for ln in ["ì¡°ë¦½1","ì¡°ë¦½2","ì¡°ë¦½3"]:
        if ln in prompt:
            return ln

    date_rows = plan_df[plan_df["plan_date"] == target_date]
    if date_rows.empty:
        return None

    up = prompt.upper()
    if "T6" in up:
        lines = date_rows[date_rows["product_name"].str.contains("T6", case=False, na=False)]["line"].unique()
        return lines[0] if len(lines) else None
    if "A2XX" in up:
        lines = date_rows[date_rows["product_name"].str.contains("A2XX", case=False, na=False)]["line"].unique()
        return lines[0] if len(lines) else None

    grp = date_rows.groupby("line")["qty_1ì°¨"].sum()
    if grp.empty:
        return None
    return grp.idxmax()

def _round_target(qty: int, unit: int) -> int:
    if unit <= 0:
        return qty
    return int(round(qty / unit) * unit)

def _ai_build_moves(prompt, target_date, target_line, need_qty, constraint_info, capa_status, from_loc):
    """
    ê°ì¶• ì „ìš© AI í”Œë˜ë„ˆ(ì˜ˆì „ ìˆ˜ì‚¬ íë¦„ì— ë§ì¶° ê°ì¶• ì´ë™ë§Œ ìƒì„±)
    """
    if not (genai and GEMINI_API_KEY):
        return []

    fact = {
        "mode": "reduce",
        "target": {"date": target_date, "line": target_line, "need_reduce_qty": int(need_qty)},
        "capa_remaining": {k: int(v["remaining"]) for k, v in capa_status.items()},
        "items": [{
            "name": x["name"],
            "plt": int(x["plt"]),
            "max_movable": int(x["max_movable"]),
            "is_t6": bool(x["is_t6"]),
            "is_a2xx": bool(x["is_a2xx"]),
            "constraint": x["constraint"],
            "priority": x["priority"],
        } for x in constraint_info[:80]],
        "from_loc": from_loc,
    }

    ai_prompt = f"""
ì•„ë˜ FACT_JSONê³¼ ê·œì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë™ ê³„íšì„ JSONìœ¼ë¡œë§Œ ì¶œë ¥í•˜ë¼.

ê·œì¹™:
1) qtyëŠ” pltì˜ ì •ìˆ˜ë°°
2) A2XXëŠ” ì¡°ë¦½3 ê¸ˆì§€
3) ì „ìš©ëª¨ë¸ì€ íƒ€ë¼ì¸ ê¸ˆì§€(ê°€ëŠ¥í•˜ë©´ ë™ì¼ë¼ì¸ ë‚ ì§œì´ë™ë§Œ)
4) ëª©ì ì§€ remaining ì´ˆê³¼ ê¸ˆì§€ (remaining ë‚´ì—ì„œ PLT ë‹¨ìœ„ë¡œ ì¡°ì •í•´ ì œì•ˆ ê°€ëŠ¥)
5) ì¶œë ¥ì€ JSONë§Œ

ì¶œë ¥ í˜•ì‹:
{{
  "moves":[
    {{"item":"í’ˆëª©","qty":ì •ìˆ˜,"from":"YYYY-MM-DD_ì¡°ë¦½X","to":"YYYY-MM-DD_ì¡°ë¦½Y","reason":"..." }}
  ]
}}

FACT_JSON:
{json.dumps(fact, ensure_ascii=False)}
"""
    try:
        model = genai.GenerativeModel("gemini-2.0-flash-exp")
        resp = model.generate_content(ai_prompt)
        raw = (resp.text or "").strip()
        raw = re.sub(r"```json\s*|\s*```", "", raw)
        s = raw.find("{")
        e = raw.rfind("}") + 1
        data = json.loads(raw[s:e])
        return data.get("moves", []) or []
    except Exception:
        return []

def _fallback_reduce(constraint_info, capa_status, from_loc, target_line, need_reduce_qty):
    moves = []
    remaining_need = int(need_reduce_qty)
    from_date, _ = from_loc.split("_", 1)

    def best_dest(keys):
        candidates = []
        for k in keys:
            if k in capa_status and int(capa_status[k]["remaining"]) > 0:
                candidates.append((int(capa_status[k]["remaining"]), k))
        candidates.sort(reverse=True)
        return [k for _, k in candidates]

    same_day_other = [k for k in best_dest([f"{from_date}_ì¡°ë¦½3", f"{from_date}_ì¡°ë¦½2", f"{from_date}_ì¡°ë¦½1"])
                      if not k.endswith(f"_{target_line}")]

    future_same_line = best_dest([k for k in capa_status.keys() if k.endswith(f"_{target_line}") and not k.startswith(from_date)])

    items_sorted = sorted(constraint_info, key=lambda x: (int(x["buffer_days"]), int(x["max_movable"])), reverse=True)

    for it in items_sorted:
        if remaining_need <= 0:
            break

        plt = int(it["plt"])
        movable = min(int(it["max_movable"]), int(it["qty_1ì°¨"]))
        movable = (movable // plt) * plt
        if movable <= 0:
            continue

        qty_to_move = min(movable, remaining_need)
        qty_to_move = (qty_to_move // plt) * plt
        if qty_to_move <= 0:
            continue

        if it["is_t6"]:
            dests = same_day_other
        elif it["is_a2xx"]:
            dests = [d for d in same_day_other if d.endswith("_ì¡°ë¦½2") or d.endswith("_ì¡°ë¦½1")]
        else:
            dests = future_same_line

        for dest in dests:
            if remaining_need <= 0 or qty_to_move <= 0:
                break
            cap = int(capa_status[dest]["remaining"])
            if cap < plt:
                continue
            move_qty = min(qty_to_move, cap)
            move_qty = (move_qty // plt) * plt
            if move_qty <= 0:
                continue

            moves.append({
                "item": it["name"],
                "qty": int(move_qty),
                "from": from_loc,
                "to": dest,
                "reason": "í´ë°±: ì œì•½/PLT/CAPA ê¸°ë°˜ ê°ì¶•"
            })
            capa_status[dest]["remaining"] = int(capa_status[dest]["remaining"]) - int(move_qty)
            remaining_need -= int(move_qty)
            qty_to_move -= int(move_qty)

    return moves

def _badge_by_remaining(remaining: int, max_capa: int) -> str:
    if max_capa <= 0:
        return "âš ï¸"
    usage = 100.0 * (max_capa - remaining) / max_capa
    if remaining <= 0 or usage >= 100:
        return "âŒ"
    if usage >= 90:
        return "âš ï¸"
    return "âœ…"

def _render_hybrid_investigation_report(
    user_prompt: str,
    today_str: str,
    target_date: str,
    target_line: str,
    stock: dict,
    target_qty: int,
    need_reduce_qty: int,
    sample_qty: int | None,
    constraint_info: list,
    capa_status: dict,
    ai_used: bool,
    ai_fail_reason: str | None,
    valid_moves: list,
    violations: list,
):
    moved = sum(int(x["qty"]) for x in (valid_moves or []))
    current_total = int(stock["total"])
    final_wo_sample = current_total - moved
    final_with_sample = final_wo_sample + (int(sample_qty) if sample_qty else 0)

    lines = []
    lines.append(user_prompt.strip())
    lines.append("")
    lines.append("âœ… [OK] í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì‚¬ ì™„ë£Œ")
    lines.append("")
    lines.append(f"ğŸ“Š {target_date} {target_line} í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì‚¬ ë³´ê³ ì„œ")
    lines.append("ğŸ” ìˆ˜ì‚¬ ë°©ì‹")
    lines.append(f"ì „ëµ ìˆ˜ë¦½: {'AI í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ (Gemini 2.0 Flash)' if ai_used else 'í´ë°± ì „ëµ (ë£° ê¸°ë°˜)'}")
    lines.append("ê²€ì¦ ì—”ì§„: Python 6ë‹¨ê³„ ê²€ì¦ âœ…")
    lines.append(f"ë¶„ì„ ê¸°ì¤€ì¼: {today_str}")
    lines.append("")

    # 1ë‹¨ê³„ í˜„í™©
    lines.append("ğŸ“‹ [1ë‹¨ê³„] í˜„í™© íŒŒì•…")
    lines.append("ê¸°ë³¸ ì •ë³´")
    lines.append(f"ëŒ€ìƒ: {target_date} / {target_line}")
    lines.append(f"í˜„ì¬ ìƒì‚°ëŸ‰: {current_total:,}ê°œ")
    util_pct = (target_qty / CAPA_LIMITS[target_line] * 100.0) if CAPA_LIMITS.get(target_line) else 0.0
    lines.append(f"ëª©í‘œ ìƒì‚°ëŸ‰: {target_qty:,}ê°œ ({util_pct:.0f}% CAPA)")
    if sample_qty:
        lines.append(f"ìƒ˜í”Œ ì¶”ê°€: {int(sample_qty):,}ê°œ")
    lines.append(f"í•„ìš” ê°ì¶•ëŸ‰: {need_reduce_qty:,}ê°œ")
    lines.append("")

    items = stock.get("items", []) or []
    lines.append(f"í’ˆëª© ëª©ë¡ ({len(items)}ê°œ)")
    for it in items[:20]:
        unit = int(it["qty_1ì°¨"]) // int(it["plt"]) if int(it["plt"]) else 0
        lines.append(f"- {it['name']}: {int(it['qty_1ì°¨']):,}ê°œ ({int(it['plt'])}PLT, ë‹¨ìœ„: {unit:,}ê°œ/PLT)")

    # 2ë‹¨ê³„ ëˆ„ì  ë‚©ê¸° ì—¬ìœ 
    lines.append("")
    lines.append("ğŸ” [2ë‹¨ê³„] ëˆ„ì  ë‚©ê¸° ì—¬ìœ  ë¶„ì„")
    movable = [x for x in constraint_info if x.get("movable")]
    lines.append(f"âœ… ì´ë™ ê°€ëŠ¥ í’ˆëª© ({len(movable)}ê°œ)")
    for idx, x in enumerate(movable[:10], 1):
        lines.append(f"{idx}. {x['name']}")
        lines.append(f"- ê³„íš ìˆ˜ëŸ‰: {int(x['qty_1ì°¨']):,}ê°œ")
        lines.append(f"- ëˆ„ì  ë‚©ê¸°: {int(x['cumsum_target']):,}ê°œ")
        lines.append(f"- ëˆ„ì  ìƒì‚°: {int(x['cumsum_actual']):,}ê°œ")
        lines.append(f"- ì´ë™ ê°€ëŠ¥ ì—¬ìœ : {int(x['max_movable']):,}ê°œ âœ…")
        lines.append(f"- ìµœì¢… ë‚©ê¸°: {x['last_due']} (ì—¬ìœ : {int(x['buffer_days'])}ì¼)")

    # 3ë‹¨ê³„ CAPA í˜„í™©
    lines.append("")
    lines.append("ğŸ¯ [3ë‹¨ê³„] ëª©ì ì§€ CAPA í˜„í™©")
    lines.append("íƒ€ë¼ì¸ ì´ì†¡ ê°€ëŠ¥ ì—¬ë¶€")
    for ln in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]:
        if ln == target_line:
            continue
        k = f"{target_date}_{ln}"
        if k in capa_status:
            rem = int(capa_status[k]["remaining"])
            mx = int(capa_status[k]["max"])
            badge = _badge_by_remaining(rem, mx)
            lines.append(f"{badge} {ln}: ì”ì—¬ {rem:,}ê°œ / {mx:,}ê°œ (ê°€ë™ë¥ : {capa_status[k]['usage_rate']:.1f}%)")

    lines.append("")
    lines.append("ë™ì¼ë¼ì¸ ì—°ê¸° ê°€ëŠ¥ ë‚ ì§œ")
    future_keys = [k for k in capa_status.keys() if k.endswith(f"_{target_line}") and not k.startswith(target_date)]
    future_keys_sorted = sorted(future_keys)[:10]
    for k in future_keys_sorted:
        rem = int(capa_status[k]["remaining"])
        mx = int(capa_status[k]["max"])
        badge = _badge_by_remaining(rem, mx)
        lines.append(f"{badge} {capa_status[k]['date']}: ì”ì—¬ {rem:,}ê°œ (ê°€ë™ë¥ : {capa_status[k]['usage_rate']:.1f}%)")

    # 4ë‹¨ê³„ ë¬¼ë¦¬ ì œì•½
    lines.append("")
    lines.append("ğŸ”’ [4ë‹¨ê³„] ë¬¼ë¦¬ ì œì•½ ì •ë³´")
    lines.append("ì œì•½ ì¡°ê±´ ìš”ì•½")
    lines.append("T6 ëª¨ë¸: ì¡°ë¦½1,2,3 ê°€ëŠ¥ (íƒ€ë¼ì¸ ì´ì†¡ ê°€ëŠ¥)")
    lines.append("A2XX ëª¨ë¸: ì¡°ë¦½1,2ë§Œ ê°€ëŠ¥ (ì¡°ë¦½3 ê¸ˆì§€)")
    lines.append("ì „ìš© ëª¨ë¸: ë™ì¼ ë¼ì¸ ë‚´ ë‚ ì§œ ì´ë™ë§Œ ê°€ëŠ¥")
    lines.append("")
    lines.append("ì´ë™ ê°€ëŠ¥ í’ˆëª© ì œì•½ í˜„í™©")
    for x in movable[:10]:
        lines.append(f"- {x['name']}: {x['constraint']} â†’ {x['priority']}")

    # 5ë‹¨ê³„ ì „ëµ
    lines.append("")
    lines.append("ğŸ¤– [5ë‹¨ê³„] ì „ëµ ìˆ˜ë¦½ ê²°ê³¼")
    if ai_used:
        lines.append("ì „ëµ ê°œìš”: AIê°€ ì œì•½/PLT/CAPAë¥¼ ê³ ë ¤í•´ ê°ì¶• ì´ë™ì•ˆì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    else:
        lines.append("ì „ëµ ê°œìš”: ë£° ê¸°ë°˜ í´ë°± ë¡œì§ìœ¼ë¡œ ê°ì¶• ì´ë™ì•ˆì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        if ai_fail_reason:
            lines.append(f"AI ë¹„ì‚¬ìš© ì‚¬ìœ : {ai_fail_reason}")

    # 6ë‹¨ê³„ ê²€ì¦
    lines.append("")
    lines.append("âœ… [6ë‹¨ê³„] Python ìµœì¢… ê²€ì¦")
    if valid_moves:
        lines.append("ê²€ì¦ ê²°ê³¼: âœ… ìŠ¹ì¸ ê°€ëŠ¥í•œ ì¡°ì¹˜ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        lines.append("")
        lines.append(f"ìµœì¢… ìŠ¹ì¸ëœ ì¡°ì¹˜ ê³„íš ({len(valid_moves)}ê°œ)")
        for i, mv in enumerate(valid_moves, 1):
            adj = ""
            if mv.get("adjusted"):
                adj = f" (ì¡°ì •: {mv.get('original_qty', 0):,}â†’{mv.get('qty', 0):,})"
            lines.append(f"ì¡°ì¹˜ {i}: {mv.get('item','')}")
            lines.append(f"- ì´ë™ëŸ‰: {int(mv.get('qty',0)):,}ê°œ{adj}")
            lines.append(f"- ì¶œë°œ: {mv.get('from','')}")
            lines.append(f"- ë„ì°©: {mv.get('to','')}")
            lines.append(f"- ì´ìœ : {mv.get('reason','')}")
            lines.append("")
    else:
        lines.append("ê²€ì¦ ê²°ê³¼: âŒ ìŠ¹ì¸ëœ ì´ë™ ê³„íšì´ ì—†ìŠµë‹ˆë‹¤.")

    if violations:
        lines.append("ê²€ì¦ ê²½ê³ /ì‹¤íŒ¨")
        for v in violations[:30]:
            lines.append(f"- {v}")

    # ìµœì¢… ê²°ê³¼
    lines.append("")
    lines.append("ğŸ¯ ìµœì¢… ê²°ê³¼")
    lines.append("í•­ëª©\tìˆ˜ì¹˜")
    lines.append(f"í˜„ì¬ ìƒì‚°ëŸ‰\t{current_total:,}ê°œ")
    lines.append(f"ëª©í‘œ ìƒì‚°ëŸ‰\t{target_qty:,}ê°œ")
    lines.append(f"í•„ìš” ê°ì¶•ëŸ‰\t{need_reduce_qty:,}ê°œ")
    lines.append(f"ì‹¤ì œ ê°ì¶•ëŸ‰\t{moved:,}ê°œ")
    lines.append(f"ì´ë™ í›„(ìƒ˜í”Œ ì œì™¸)\t{final_wo_sample:,}ê°œ")
    if sample_qty:
        lines.append(f"ìƒ˜í”Œ í¬í•¨ ìµœì¢…\t{final_with_sample:,}ê°œ")

    # ë‹¬ì„±ë¥ : ê°ì¶• ê¸°ì¤€
    achieve = (moved / need_reduce_qty * 100.0) if need_reduce_qty else 0.0
    lines.append(f"ëª©í‘œ ë‹¬ì„±ë¥ \t{achieve:.1f}%")

    lines.append("")
    lines.append("ğŸ“‹ ìƒì„¸ ë°ì´í„° ë³´ê¸°")
    return "\n".join(lines)

def _render_hybrid_simple_report(target_date, target_line, stock_total, target_qty, need_reduce_qty, valid_moves, violations, ai_used, ai_failed_reason=None):
    moved = sum(int(x["qty"]) for x in (valid_moves or []))
    final_qty = stock_total - moved
    achieve = (moved / need_reduce_qty * 100.0) if need_reduce_qty else 0.0

    out = []
    out.append("[í•˜ì´ë¸Œë¦¬ë“œ ê°ì¶• ê²°ê³¼]")
    out.append(f"- ëŒ€ìƒ: {target_date} {target_line}")
    out.append(f"- í˜„ì¬: {stock_total:,}")
    out.append(f"- ëª©í‘œ: {target_qty:,}")
    out.append(f"- í•„ìš” ê°ì¶•: {need_reduce_qty:,}")
    out.append(f"- ì‹¤ì œ ê°ì¶•: {moved:,} (ë‹¬ì„±ë¥  {achieve:.1f}%)")
    out.append(f"- ìµœì¢…: {final_qty:,}")
    out.append("")
    out.append(f"- ê³„íš ìƒì„±: {'AI' if ai_used else 'í´ë°±'}" + (f" (AI ì‹¤íŒ¨: {ai_failed_reason})" if ai_failed_reason else ""))

    if valid_moves:
        out.append("\n[ìŠ¹ì¸ëœ ì´ë™ ê³„íš]")
        for i, mv in enumerate(valid_moves, 1):
            adj = ""
            if mv.get("adjusted"):
                adj = f" (ì¡°ì •: {mv.get('original_qty', 0):,}â†’{mv.get('qty',0):,})"
            out.append(f"{i}. {mv.get('item','')} | {int(mv.get('qty',0)):,}{adj} | {mv.get('from','')} â†’ {mv.get('to','')} | {mv.get('reason','')}")
    else:
        out.append("\nìŠ¹ì¸ëœ ì´ë™ ê³„íšì´ ì—†ìŠµë‹ˆë‹¤.")

    if violations:
        out.append("\n[ê²€ì¦ ê²½ê³ /ì‹¤íŒ¨]")
        out.extend([f"- {v}" for v in violations[:40]])

    return "\n".join(out)

def run_hybrid(prompt: str) -> str:
    if supabase is None:
        return "SUPABASE_URL/SUPABASE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í•˜ì´ë¸Œë¦¬ë“œ DB ì¡°íšŒë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”."

    target_date = _extract_date_any(prompt, default_year="2026")
    if not target_date:
        return "ì¡°ì • ìš”ì²­ìœ¼ë¡œ ë³´ì´ì§€ë§Œ ë‚ ì§œë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ˆ: `1/21 T6 ìƒ˜í”Œ 100ê°œ ì¶”ê°€` ë˜ëŠ” `2026-01-21 ...`"

    today = _get_hybrid_today()
    capa_limits = CAPA_LIMITS_DEFAULT if isinstance(CAPA_LIMITS_DEFAULT, dict) else {"ì¡°ë¦½1": 3300, "ì¡°ë¦½2": 3700, "ì¡°ë¦½3": 3600}
    initialize_globals(today, capa_limits)

    plan_df, _hist_df = fetch_data_hybrid(target_date)
    if plan_df.empty:
        return f"{target_date} ê¸°ì¤€ ìƒì‚°ê³„íš ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(í…Œì´ë¸”/ë‚ ì§œ í™•ì¸ í•„ìš”: {HYBRID_PLAN_TABLE})."

    target_line = _pick_target_line(prompt, plan_df, target_date)
    if not target_line:
        return "ëŒ€ìƒ ë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `ì¡°ë¦½1/2/3` ë˜ëŠ” í’ˆëª© íŒíŠ¸(T6/A2XX)ë¥¼ í¬í•¨í•´ì„œ ì…ë ¥í•˜ì„¸ìš”."

    stock, err = step1_list_current_stock(plan_df, target_date, target_line)
    if err:
        return err

    items_slack = step2_calculate_cumulative_slack(plan_df, stock)
    constraint_info = step4_prepare_constraint_info(items_slack, target_line)
    capa_status = step3_analyze_destination_capacity(plan_df, target_date, target_line)

    # --- intent parsing ---
    pct = _parse_target_percent(prompt)
    if pct is None:
        pct = HYBRID_DEFAULT_TARGET_UTIL

    # ëª©í‘œ ìƒì‚°ëŸ‰: ì˜ˆì „ ë¦¬í¬íŠ¸ ëŠë‚Œ(ì˜ˆ: 81% CAPA, 100ë‹¨ìœ„ ë°˜ì˜¬ë¦¼)
    raw_target = int(CAPA_LIMITS[target_line] * float(pct))
    target_qty = _round_target(raw_target, HYBRID_TARGET_ROUNDING)

    sample_qty = _parse_sample_qty(prompt)  # "ìƒ˜í”Œ 100"
    add_qty = _parse_add_qty(prompt)        # "ì¶”ê°€ 100" (ìƒ˜í”Œ ì—†ì´ë„)

    # ì‹œë‚˜ë¦¬ì˜¤:
    # - "ìƒ˜í”Œ N ì¶”ê°€" => ìƒ˜í”Œì´ ë“¤ì–´ì˜¤ë©´ ë‹¹ì¼ ê³„íšì„ ê°ì¶•/ì´ì†¡í•´ì„œ ëª©í‘œ ê°€ë™ë¥ (=target_qty) ì´ë‚´ë¡œ ë§ì¶”ëŠ” ìˆ˜ì‚¬
    # - ê·¸ ì™¸ % ê¸°ë°˜ ê°ì¶• ìˆ˜ì‚¬
    if sample_qty is not None:
        # ìƒ˜í”Œ í¬í•¨ ì˜ˆìƒ ì´ëŸ‰ì´ ëª©í‘œ ì´ˆê³¼í•˜ë©´ ê·¸ ì´ˆê³¼ë¶„ë§Œí¼ ê°ì¶•, ì•„ë‹ˆë©´ "ìƒ˜í”Œ ì¶”ê°€í•´ë„ ëª©í‘œ ì´ë‚´" ì•ˆë‚´
        expected_with_sample = int(stock["total"]) + int(sample_qty)
        need_reduce_qty = max(0, expected_with_sample - int(target_qty))
        if need_reduce_qty == 0:
            # ì˜ˆì „ì²˜ëŸ¼ ë¦¬í¬íŠ¸ í¬ë§·ì€ ìœ ì§€í•˜ë˜, ì¡°ì¹˜ ì—†ìŒìœ¼ë¡œ ì•ˆë‚´
            if HYBRID_REPORT_STYLE == "investigation":
                return _render_hybrid_investigation_report(
                    user_prompt=prompt,
                    today_str=today.strftime("%Y-%m-%d"),
                    target_date=target_date,
                    target_line=target_line,
                    stock=stock,
                    target_qty=int(target_qty),
                    need_reduce_qty=0,
                    sample_qty=int(sample_qty),
                    constraint_info=constraint_info,
                    capa_status=capa_status,
                    ai_used=False,
                    ai_fail_reason="ìƒ˜í”Œ ì¶”ê°€ í›„ì—ë„ ëª©í‘œ ì´í•˜(ê°ì¶• ë¶ˆí•„ìš”)",
                    valid_moves=[],
                    violations=[],
                )
            return f"[í˜„í™©]\n- ëŒ€ìƒ: {target_date} {target_line}\n- í˜„ì¬: {stock['total']:,}\n- ìƒ˜í”Œ ì¶”ê°€: {int(sample_qty):,}\n- ëª©í‘œ: {target_qty:,}\n\nìƒ˜í”Œ ì¶”ê°€ í›„ì—ë„ ëª©í‘œ ìƒì‚°ëŸ‰ ì´ë‚´ë¼ ê°ì¶• ì¡°ì¹˜ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤."

        # ê°ì¶• ìˆ˜ì‚¬ ìˆ˜í–‰
    else:
        # % ê¸°ë°˜ ê°ì¶•: í˜„ì¬ê°€ ëª©í‘œ ì´í•˜ì´ë©´ ê°ì¶• ë¶ˆí•„ìš”
        need_reduce_qty = int(stock["total"] - target_qty)
        if need_reduce_qty <= 0:
            if HYBRID_REPORT_STYLE == "investigation":
                return _render_hybrid_investigation_report(
                    user_prompt=prompt,
                    today_str=today.strftime("%Y-%m-%d"),
                    target_date=target_date,
                    target_line=target_line,
                    stock=stock,
                    target_qty=int(target_qty),
                    need_reduce_qty=0,
                    sample_qty=None,
                    constraint_info=constraint_info,
                    capa_status=capa_status,
                    ai_used=False,
                    ai_fail_reason="í˜„ì¬ ìƒì‚°ëŸ‰ì´ ëª©í‘œ ì´í•˜(ê°ì¶• ë¶ˆí•„ìš”)",
                    valid_moves=[],
                    violations=[],
                )
            return (
                f"[í˜„í™©]\n- ëŒ€ìƒ: {target_date} {target_line}\n"
                f"- í˜„ì¬: {stock['total']:,}\n- ëª©í‘œ: {target_qty:,}\n\n"
                f"í˜„ì¬ ìƒì‚°ëŸ‰ì´ ëª©í‘œ ì´í•˜ë¼ ê°ì¶• ì¡°ì¹˜ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤."
            )

    # locations (reduce)
    from_loc = f"{target_date}_{target_line}"

    # 1) AI plan (optional)
    ai_used = False
    ai_fail_reason = None
    moves = []

    if genai and GEMINI_API_KEY and constraint_info:
        ai_moves = _ai_build_moves(
            prompt=prompt,
            target_date=target_date,
            target_line=target_line,
            need_qty=int(abs(need_reduce_qty)),
            constraint_info=constraint_info,
            capa_status=capa_status,
            from_loc=from_loc,
        )
        if ai_moves:
            moves = ai_moves
            ai_used = True
        else:
            ai_fail_reason = "AI ê²°ê³¼ ì—†ìŒ/íŒŒì‹± ì‹¤íŒ¨"

    # 2) fallback
    if not moves:
        capa_copy = {k: dict(v) for k, v in capa_status.items()}
        moves = _fallback_reduce(constraint_info, capa_copy, from_loc, target_line, abs(need_reduce_qty))
        ai_used = False

    # 3) validate (with adjust)
    capa_for_validate = {k: dict(v) for k, v in capa_status.items()}
    valid_moves, violations = step6_validate_moves_with_adjust(
        moves=moves,
        constraint_info=constraint_info,
        capa_status=capa_for_validate,
        plan_df=plan_df,
        target_line=target_line
    )

    if HYBRID_REPORT_STYLE == "investigation":
        return _render_hybrid_investigation_report(
            user_prompt=prompt,
            today_str=today.strftime("%Y-%m-%d"),
            target_date=target_date,
            target_line=target_line,
            stock=stock,
            target_qty=int(target_qty),
            need_reduce_qty=int(abs(need_reduce_qty)),
            sample_qty=int(sample_qty) if sample_qty is not None else None,
            constraint_info=constraint_info,
            capa_status=capa_status,
            ai_used=ai_used,
            ai_fail_reason=ai_fail_reason,
            valid_moves=valid_moves,
            violations=violations
        )

    return _render_hybrid_simple_report(
        target_date=target_date,
        target_line=target_line,
        stock_total=int(stock["total"]),
        target_qty=int(target_qty),
        need_reduce_qty=int(abs(need_reduce_qty)),
        valid_moves=valid_moves,
        violations=violations,
        ai_used=ai_used,
        ai_failed_reason=ai_fail_reason
    )


# =============================================================================
# Entry
# =============================================================================

def route_and_answer(prompt: str) -> tuple[str, dict]:
    route, meta = classify_route(prompt)
    if route == "hybrid":
        ans = run_hybrid(prompt)
    else:
        ans = run_legacy(prompt)

    debug = {"route": route, **meta}
    return ans, debug
